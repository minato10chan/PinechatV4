import streamlit as st
from src.utils.text_processing import process_text_file
from src.services.pinecone_service import PineconeService
from src.services.category_classifier import CategoryClassifier
from src.services.response_templates import QuestionExampleGenerator
from src.config.settings import METADATA_CATEGORIES
from datetime import datetime
import pandas as pd
import json
import traceback
import io
import re
from typing import List, Dict, Any

def read_file_content(file) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’é©åˆ‡ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã‚€"""
    encodings = ['utf-8', 'shift-jis', 'cp932', 'euc-jp']
    content = file.getvalue()
    
    for encoding in encodings:
        try:
            # ãƒã‚¤ãƒˆåˆ—ã‚’æ–‡å­—åˆ—ã«ãƒ‡ã‚³ãƒ¼ãƒ‰
            decoded_content = content.decode(encoding)
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ãŸæ–‡å­—åˆ—ã‚’å†åº¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦å…ƒã®ãƒã‚¤ãƒˆåˆ—ã¨æ¯”è¼ƒ
            if decoded_content.encode(encoding) == content:
                return decoded_content
        except (UnicodeDecodeError, UnicodeEncodeError):
            continue
    
    # ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§å¤±æ•—ã—ãŸå ´åˆ
    try:
        # UTF-8ã§å¼·åˆ¶çš„ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’è©¦ã¿ã‚‹ï¼ˆä¸€éƒ¨ã®æ–‡å­—ãŒåŒ–ã‘ã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
        return content.decode('utf-8', errors='replace')
    except Exception as e:
        raise ValueError(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_csv_file(file):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    try:
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒªã‚¹ãƒˆï¼ˆæ—¥æœ¬èªã®CSVã§ä¸€èˆ¬çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
        encodings = ['utf-8', 'shift-jis', 'cp932', 'euc-jp']
        
        # å„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§è©¦è¡Œ
        for encoding in encodings:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒã‚¤ãƒˆåˆ—ã¨ã—ã¦èª­ã¿è¾¼ã‚€
                content = file.getvalue()
                # æŒ‡å®šã—ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒ‡ã‚³ãƒ¼ãƒ‰
                decoded_content = content.decode(encoding)
                # ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ãŸå†…å®¹ã‚’StringIOã«å¤‰æ›
                file_like = io.StringIO(decoded_content)
                # CSVã¨ã—ã¦èª­ã¿è¾¼ã‚€
                df = pd.read_csv(file_like, header=None, names=[
                    "å¤§ã‚«ãƒ†ã‚´ãƒª", "ä¸­ã‚«ãƒ†ã‚´ãƒª", "æ–½è¨­å", "ç·¯åº¦", "çµŒåº¦", "å¾’æ­©è·é›¢", "å¾’æ­©åˆ†æ•°", "ç›´ç·šè·é›¢"
                ])
                break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            except (UnicodeDecodeError, pd.errors.EmptyDataError):
                continue  # å¤±æ•—ã—ãŸã‚‰æ¬¡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
        
        if 'df' not in locals():
            raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        st.write("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹:")
        st.dataframe(df)
        
        # å„åˆ—ã‚’çµåˆã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        chunks = []
        for index, row in df.iterrows():
            try:
                # å„è¡Œã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
                text = f"{row['æ–½è¨­å']}ã¯{row['å¤§ã‚«ãƒ†ã‚´ãƒª']}ã®{row['ä¸­ã‚«ãƒ†ã‚´ãƒª']}ã§ã™ã€‚"
                if text.strip():
                    # NaNå€¤ã‚’é©åˆ‡ã«å‡¦ç†ã—ã€å‹å¤‰æ›ã‚’ç¢ºå®Ÿã«è¡Œã†
                    metadata = {
                        "main_category": str(row['å¤§ã‚«ãƒ†ã‚´ãƒª']) if pd.notna(row['å¤§ã‚«ãƒ†ã‚´ãƒª']) else "",
                        "sub_category": str(row['ä¸­ã‚«ãƒ†ã‚´ãƒª']) if pd.notna(row['ä¸­ã‚«ãƒ†ã‚´ãƒª']) else "",
                        "facility_name": str(row['æ–½è¨­å']) if pd.notna(row['æ–½è¨­å']) else "",
                        "latitude": float(row['ç·¯åº¦']) if pd.notna(row['ç·¯åº¦']) else 0.0,
                        "longitude": float(row['çµŒåº¦']) if pd.notna(row['çµŒåº¦']) else 0.0,
                        "walking_distance": int(float(row['å¾’æ­©è·é›¢'])) if pd.notna(row['å¾’æ­©è·é›¢']) else 0,
                        "walking_minutes": int(float(row['å¾’æ­©åˆ†æ•°'])) if pd.notna(row['å¾’æ­©åˆ†æ•°']) else 0,
                        "straight_distance": int(float(row['ç›´ç·šè·é›¢'])) if pd.notna(row['ç›´ç·šè·é›¢']) else 0
                    }
                    
                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
                    st.write(f"è¡Œ {index + 1} ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
                    st.json(metadata)
                    
                    chunks.append({
                        "id": f"csv_{index}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                        "text": text,
                        "metadata": metadata
                    })
            except Exception as e:
                st.error(f"è¡Œ {index + 1} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                continue
        
        if not chunks:
            raise ValueError("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
        return chunks
    except Exception as e:
        raise ValueError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

def manual_chunk_split(text: str, chunk_separators: str = "---") -> List[Dict[str, Any]]:
    """æ‰‹å‹•ã§ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†å‰²"""
    chunks = []
    
    # ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
    if chunk_separators:
        # è¤‡æ•°ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆæ”¹è¡Œã§åŒºåˆ‡ã‚‹ï¼‰
        separators = [sep.strip() for sep in chunk_separators.split('\n') if sep.strip()]
        
        # æœ€åˆã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã§åˆ†å‰²
        if separators:
            parts = text.split(separators[0])
        else:
            parts = [text]
    else:
        parts = [text]
    
    # å„éƒ¨åˆ†ã‚’ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦å‡¦ç†
    for i, part in enumerate(parts):
        part = part.strip()
        if part:  # ç©ºã§ãªã„éƒ¨åˆ†ã®ã¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦è¿½åŠ 
            chunks.append({
                "id": f"manual_chunk_{i}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "text": part,
                "metadata": {
                    "chunk_type": "manual",
                    "chunk_index": i
                }
            })
    
    return chunks

def advanced_manual_chunk_split(text: str, chunk_separators: str = "---") -> List[Dict[str, Any]]:
    """é«˜åº¦ãªæ‰‹å‹•ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆè¤‡æ•°ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
    chunks = []
    
    if not chunk_separators:
        # ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦æ‰±ã†
        if text.strip():
            chunks.append({
                "id": f"manual_chunk_0_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "text": text.strip(),
                "metadata": {
                    "chunk_type": "manual",
                    "chunk_index": 0
                }
            })
        return chunks
    
    # è¤‡æ•°ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆæ”¹è¡Œã§åŒºåˆ‡ã‚‹ï¼‰
    separators = [sep.strip() for sep in chunk_separators.split('\n') if sep.strip()]
    
    if not separators:
        # æœ‰åŠ¹ãªã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ãŒãªã„å ´åˆ
        if text.strip():
            chunks.append({
                "id": f"manual_chunk_0_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "text": text.strip(),
                "metadata": {
                    "chunk_type": "manual",
                    "chunk_index": 0
                }
            })
        return chunks
    
    # æœ€åˆã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã§åˆ†å‰²
    parts = text.split(separators[0])
    
    # å„éƒ¨åˆ†ã‚’å‡¦ç†
    chunk_index = 0
    for part in parts:
        part = part.strip()
        if not part:  # ç©ºã®éƒ¨åˆ†ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
        
        # è¿½åŠ ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã€ã•ã‚‰ã«åˆ†å‰²ã‚’è©¦ã¿ã‚‹
        if len(separators) > 1:
            sub_parts = []
            current_part = part
            
            for sep in separators[1:]:
                if sep in current_part:
                    sub_parts.extend(current_part.split(sep))
                    current_part = ""
                    break
                else:
                    sub_parts = [current_part]
                    break
            
            # ã‚µãƒ–ãƒ‘ãƒ¼ãƒ„ã‚’å‡¦ç†
            for sub_part in sub_parts:
                sub_part = sub_part.strip()
                if sub_part:  # ç©ºã§ãªã„éƒ¨åˆ†ã®ã¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦è¿½åŠ 
                    chunks.append({
                        "id": f"manual_chunk_{chunk_index}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                        "text": sub_part,
                        "metadata": {
                            "chunk_type": "manual",
                            "chunk_index": chunk_index,
                            "separators_used": separators
                        }
                    })
                    chunk_index += 1
        else:
            # å˜ä¸€ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®å ´åˆ
            chunks.append({
                "id": f"manual_chunk_{chunk_index}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "text": part,
                "metadata": {
                    "chunk_type": "manual",
                    "chunk_index": chunk_index,
                    "separators_used": separators
                }
            })
            chunk_index += 1
    
    return chunks

def preview_chunks(text: str, chunk_separators: str = "---") -> List[Dict[str, Any]]:
    """ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"""
    return advanced_manual_chunk_split(text, chunk_separators)

def render_file_upload(pinecone_service: PineconeService):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®UIã‚’è¡¨ç¤º"""
    st.title("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.write("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Pineconeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚")
    
    uploaded_file = st.file_uploader("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt', 'csv'])
    
    if uploaded_file is not None:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¨®é¡ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        if file_extension == 'csv':
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã—ãªã„
            if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"):
                try:
                    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
                        chunks = process_csv_file(uploaded_file)
                        st.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
                        
                        with st.spinner("Pineconeã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                            pinecone_service.upload_chunks(chunks)
                            st.success("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                except ValueError as e:
                    st.error(str(e))
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º
            st.subheader("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
            
            # å¸‚åŒºç”ºæ‘ã®é¸æŠ
            city = st.selectbox(
                "å¸‚åŒºç”ºæ‘",
                METADATA_CATEGORIES["å¸‚åŒºç”ºæ‘"],
                index=None,
                placeholder="å¸‚åŒºç”ºæ‘ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰"
            )
            
            # ãƒ‡ãƒ¼ã‚¿ä½œæˆæ—¥ã®é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å½“æ—¥ã€è¡¨ç¤ºéè¡¨ç¤ºï¼‰
            created_date = datetime.now().date()
            
            # ã‚½ãƒ¼ã‚¹å…ƒã®å…¥åŠ›
            source = st.text_input(
                "ã‚½ãƒ¼ã‚¹å…ƒ",
                placeholder="ã‚½ãƒ¼ã‚¹å…ƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰"
            )
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çŠ¶æ³
            st.markdown("#### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»æœ‰åŠ¹æ€§è¨­å®š")
            
            # æ¤œè¨¼æ¸ˆã¿ãƒ•ãƒ©ã‚°
            verified = st.checkbox(
                "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æ¸ˆã¿",
                value=False,
                help="ã“ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¤œè¨¼æ¸ˆã¿ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™"
            )
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚¿ã‚¤ãƒ—ï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼‰
            timestamp_type = st.radio(
                "ğŸ“… ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¿ã‚¤ãƒ—",
                options=[
                    ("fixed", "å›ºå®šãƒ‡ãƒ¼ã‚¿"),
                    ("yearly", "å¹´æ¬¡æ›´æ–°"),
                    ("dated", "æ—¥ä»˜æŒ‡å®š")
                ],
                format_func=lambda x: x[1],
                index=0,
                help="ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°é »åº¦ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
            # ã‚¿ãƒ—ãƒ«ã‹ã‚‰æ–‡å­—åˆ—ã«å¤‰æ›
            timestamp_type = timestamp_type[0] if isinstance(timestamp_type, tuple) else timestamp_type
            
            # æœ‰åŠ¹æœŸé–“ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ï¼‰- å°ã•ãã™ã‚‹
            st.markdown("**ğŸ“† ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆå¹´åº¦**")
            st.markdown("ã“ã®ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆå¹´åº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šä»¤å’Œ6å¹´åº¦ã€è¤‡æ•°å¯ï¼‰")
            
            valid_for_text = st.text_input(
                "ä½œæˆå¹´åº¦",
                value="ä»¤å’Œ6å¹´åº¦",
                placeholder="ä½œæˆå¹´åº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šä»¤å’Œ6å¹´åº¦ã€ä»¤å’Œ5å¹´åº¦ã€2024å¹´åº¦ï¼‰",
                help="ã“ã®ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆå¹´åº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°ã®å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰"
            )
            selected_periods = [p.strip() for p in valid_for_text.split(',') if p.strip()] if valid_for_text.strip() else []
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ—¥ï¼ˆè‡ªå‹•è¨­å®šï¼‰
            upload_date = datetime.now()
            
            # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ–¹æ³•ã®é¸æŠ
            st.subheader("ğŸ“ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²è¨­å®š")
            st.info("ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã¯æ‰‹å‹•ã§è¡Œã„ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’ç·¨é›†ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã®å¢ƒç•Œã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®èª­ã¿è¾¼ã¿
            file_content = read_file_content(uploaded_file)
            
            # æ‰‹å‹•åˆ†å‰²ãƒ¢ãƒ¼ãƒ‰ï¼ˆå”¯ä¸€ã®é¸æŠè‚¢ï¼‰
            st.markdown("### âœï¸ æ‰‹å‹•ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²")
            st.markdown("ãƒ†ã‚­ã‚¹ãƒˆã‚’ç·¨é›†ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã®å¢ƒç•Œã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            
            # ãƒãƒ£ãƒ³ã‚¯ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®è¨­å®š
            st.markdown("#### ğŸ“‹ ãƒãƒ£ãƒ³ã‚¯ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿")
            st.markdown("ãƒãƒ£ãƒ³ã‚¯ã‚’åŒºåˆ‡ã‚‹æ–‡å­—åˆ—ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯æ”¹è¡Œã§åŒºåˆ‡ã£ã¦ãã ã•ã„ã€‚")
            
            # ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®ä¾‹
            with st.expander("ğŸ’¡ ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®ä¾‹", expanded=False):
                st.markdown("**åŸºæœ¬çš„ãªã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿:**")
                st.code("---\n###\n##\n#")
                
                st.markdown("**æ®µè½åŒºåˆ‡ã‚Š:**")
                st.code("\\n\\n\n---\n***")
                
                st.markdown("**è¦‹å‡ºã—åŒºåˆ‡ã‚Š:**")
                st.code("ç¬¬1ç« \nç¬¬2ç« \nç¬¬3ç« \n\n1.\n2.\n3.")
                
                st.markdown("**ã‚«ã‚¹ã‚¿ãƒ åŒºåˆ‡ã‚Š:**")
                st.code("ã€ç‰©ä»¶æ¦‚è¦ã€‘\nã€äº¤é€šã‚¢ã‚¯ã‚»ã‚¹ã€‘\nã€å‘¨è¾ºç’°å¢ƒã€‘\n\n=== ç‰©ä»¶æƒ…å ± ===\n=== ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ± ===")
                
                st.markdown("**ä½¿ç”¨æ–¹æ³•:**")
                st.markdown("1. ä¸Šè¨˜ã®ä¾‹ã‹ã‚‰é©åˆ‡ãªã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼")
                st.markdown("2. ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è²¼ã‚Šä»˜ã‘")
                st.markdown("3. å¿…è¦ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º")
                st.markdown("4. ãƒ†ã‚­ã‚¹ãƒˆå†…ã«ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’åŒºåˆ‡ã‚‹")
            
            default_separators = "---\n###\n##"
            chunk_separators = st.text_area(
                "ãƒãƒ£ãƒ³ã‚¯ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿",
                value=default_separators,
                height=100,
                help="ãƒãƒ£ãƒ³ã‚¯ã‚’åŒºåˆ‡ã‚‹æ–‡å­—åˆ—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è¤‡æ•°ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯æ”¹è¡Œã§åŒºåˆ‡ã£ã¦ãã ã•ã„ã€‚ä¾‹ï¼š---, ###, ## ãªã©"
            )
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ‡ã‚£ã‚¿
            st.markdown("#### ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†")
            st.markdown("å¿…è¦ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç·¨é›†ã—ã€ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’åŒºåˆ‡ã£ã¦ãã ã•ã„ã€‚")
            
            edited_text = st.text_area(
                "ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹",
                value=file_content,
                height=400,
                help="ãƒ†ã‚­ã‚¹ãƒˆã‚’ç·¨é›†ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã®å¢ƒç•Œã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
            )
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒœã‚¿ãƒ³
            if st.button("ğŸ‘ï¸ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆ
                preview_chunks_list = preview_chunks(edited_text, chunk_separators)
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state['preview_chunks'] = preview_chunks_list
                st.session_state['show_preview'] = True
                
                st.success(f"âœ… {len(preview_chunks_list)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã«ç”Ÿæˆã—ã¾ã—ãŸ")
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆ
            if st.session_state.get('show_preview', False) and 'preview_chunks' in st.session_state:
                preview_chunks_list = st.session_state['preview_chunks']
                
                st.markdown("#### ğŸ“‹ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                
                if preview_chunks_list:
                    st.success(f"âœ… {len(preview_chunks_list)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã•ã‚Œã¾ã—ãŸ")
                    
                    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                    total_chars = sum(len(chunk['text']) for chunk in preview_chunks_list)
                    avg_chars = total_chars // len(preview_chunks_list) if preview_chunks_list else 0
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ãƒãƒ£ãƒ³ã‚¯æ•°", len(preview_chunks_list))
                    with col2:
                        st.metric("ç·æ–‡å­—æ•°", total_chars)
                    with col3:
                        st.metric("å¹³å‡æ–‡å­—æ•°", avg_chars)
                    
                    # å„ãƒãƒ£ãƒ³ã‚¯ã‚’è¡¨ç¤º
                    for i, chunk in enumerate(preview_chunks_list):
                        # ãƒãƒ£ãƒ³ã‚¯ã®æ¦‚è¦æƒ…å ±ã‚’ä½œæˆ
                        chunk_summary = f"ğŸ“„ ãƒãƒ£ãƒ³ã‚¯ {i+1}"
                        if 'ai_classification' in chunk:
                            ai_result = chunk['ai_classification']
                            main_cat = ai_result.get('main_category', 'æœªåˆ†é¡')
                            sub_cat = ai_result.get('sub_category', 'æœªåˆ†é¡')
                            chunk_summary += f" | ğŸ·ï¸ {main_cat}/{sub_cat}"
                        elif 'manual_main_category' in chunk and chunk['manual_main_category']:
                            chunk_summary += f" | ğŸ·ï¸ {chunk['manual_main_category']}/{chunk.get('manual_sub_category', '')}"
                        else:
                            chunk_summary += " | ğŸ·ï¸ æœªåˆ†é¡"
                        
                        chunk_summary += f" | ğŸ“ {len(chunk['text'])}æ–‡å­—"
                        
                        # ä½ç½®æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                        if chunk.get('chunk_location', {}).get('latitude') is not None:
                            chunk_summary += " | ğŸ“ ä½ç½®æƒ…å ±ã‚ã‚Š"
                        
                        # è³ªå•ä¾‹ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                        if chunk.get('question_examples'):
                            chunk_summary += f" | ğŸ’¬ {len(chunk['question_examples'])}å€‹ã®è³ªå•ä¾‹"
                        
                        # å›ç­”ä¾‹ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                        if chunk.get('answer_examples'):
                            chunk_summary += f" | ğŸ’¡ {len(chunk['answer_examples'])}å€‹ã®å›ç­”ä¾‹"
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§é–‹é–‰çŠ¶æ…‹ã‚’ç®¡ç†
                        expander_key = f"chunk_expander_{i}"
                        if expander_key not in st.session_state:
                            st.session_state[expander_key] = False
                        
                        # è³ªå•ä¾‹ç”Ÿæˆã‚„AIåˆ†é¡ãŒå®Ÿè¡Œã•ã‚ŒãŸå ´åˆã¯é–‹ã„ãŸçŠ¶æ…‹ã«ã™ã‚‹
                        if (f"generate_questions_{i}" in st.session_state and st.session_state[f"generate_questions_{i}"]) or \
                           (f"improve_questions_{i}" in st.session_state and st.session_state[f"improve_questions_{i}"]) or \
                           (f"ai_classify_{i}" in st.session_state and st.session_state[f"ai_classify_{i}"]):
                            st.session_state[expander_key] = True
                            # ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                            st.session_state[f"generate_questions_{i}"] = False
                            st.session_state[f"improve_questions_{i}"] = False
                            st.session_state[f"ai_classify_{i}"] = False
                        
                        with st.expander(chunk_summary, expanded=st.session_state[expander_key]):
                            # ãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°æƒ…å ±
                            st.markdown(f"**ãƒãƒ£ãƒ³ã‚¯ID:** {chunk['id']}")
                            st.markdown(f"**æ–‡å­—æ•°:** {len(chunk['text'])}æ–‡å­—")
                            if 'separators_used' in chunk['metadata']:
                                st.markdown(f"**ä½¿ç”¨ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿:** {', '.join(chunk['metadata']['separators_used'])}")
                            
                            # ãƒãƒ£ãƒ³ã‚¯å†…å®¹ã®è¡¨ç¤º
                            st.text_area(
                                f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å†…å®¹",
                                value=chunk['text'],
                                height=150,
                                key=f"preview_chunk_{i}"
                            )
                            
                            # ã‚«ãƒ†ã‚´ãƒªè¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
                            st.markdown("#### ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªè¨­å®š")
                            
                            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡å™¨ã‚’åˆæœŸåŒ–
                            classifier = CategoryClassifier()
                            
                            # AIåˆ†é¡ãƒœã‚¿ãƒ³ï¼ˆãƒãƒ£ãƒ³ã‚¯ã”ã¨ï¼‰
                            if st.button(f"ğŸ¤– AIã§ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•åˆ¤å®š", key=f"ai_classify_{i}"):
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¨­å®šã—ã¦expanderã‚’é–‹ã„ãŸçŠ¶æ…‹ã«ã™ã‚‹
                                st.session_state[f"ai_classify_{i}"] = True
                                st.session_state[f"chunk_expander_{i}"] = True
                                
                                try:
                                    with st.spinner(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã‚’åˆ†æä¸­..."):
                                        # AIåˆ†é¡ã‚’å®Ÿè¡Œ
                                        classification = classifier.classify_text(chunk['text'])
                                        
                                        # åˆ†é¡çµæœã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                                        chunk['ai_classification'] = classification
                                        
                                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                                        st.session_state['preview_chunks'] = preview_chunks_list
                                        
                                        st.success(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®åˆ†é¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                        st.write(f"åˆ†é¡çµæœ: {classification.get('main_category', 'æœªåˆ†é¡')} / {classification.get('sub_category', 'æœªåˆ†é¡')}")
                                        
                                except Exception as e:
                                    st.error(f"AIåˆ†é¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            
                            # AIåˆ†é¡çµæœã®è¡¨ç¤º
                            if 'ai_classification' in chunk:
                                ai_result = chunk['ai_classification']
                                st.markdown("**ğŸ¤– AIåˆ†é¡çµæœ:**")
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.markdown(f"**å¤§ã‚«ãƒ†ã‚´ãƒª:** {ai_result.get('main_category', 'æœªåˆ†é¡')}")
                                    st.markdown(f"**ä¸­ã‚«ãƒ†ã‚´ãƒª:** {ai_result.get('sub_category', 'æœªåˆ†é¡')}")
                                with col2:
                                    confidence = ai_result.get('confidence', 0.0)
                                    st.markdown(f"**ç¢ºä¿¡åº¦:** {confidence:.2%}")
                                
                                st.markdown(f"**åˆ†é¡ç†ç”±:** {ai_result.get('reasoning', 'ç†ç”±ãªã—')}")
                                
                                # ç¢ºä¿¡åº¦ã«å¿œã˜ãŸè‰²åˆ†ã‘
                                if confidence >= 0.8:
                                    st.success("âœ… é«˜ç¢ºä¿¡åº¦")
                                elif confidence >= 0.6:
                                    st.warning("âš ï¸ ä¸­ç¢ºä¿¡åº¦")
                                else:
                                    st.error("âŒ ä½ç¢ºä¿¡åº¦")
                            
                            # æ‰‹å‹•ã‚«ãƒ†ã‚´ãƒªç·¨é›†
                            st.markdown("**âœï¸ ã‚«ãƒ†ã‚´ãƒªæ‰‹å‹•ç·¨é›†:**")
                            
                            # ç¾åœ¨ã®AIåˆ†é¡çµæœã‚’åˆæœŸå€¤ã¨ã—ã¦ä½¿ç”¨
                            current_main = ai_result.get('main_category', '') if 'ai_classification' in chunk else ''
                            current_sub = ai_result.get('sub_category', '') if 'ai_classification' in chunk else ''
                            
                            # å¤§ã‚«ãƒ†ã‚´ãƒªã®é¸æŠ
                            main_category_options = [''] + classifier.get_main_categories()
                            main_category_index = main_category_options.index(current_main) if current_main in main_category_options else 0
                            
                            selected_main = st.selectbox(
                                "å¤§ã‚«ãƒ†ã‚´ãƒª",
                                options=main_category_options,
                                index=main_category_index,
                                key=f"main_cat_{i}"
                            )
                            
                            # ä¸­ã‚«ãƒ†ã‚´ãƒªã®é¸æŠ
                            if selected_main:
                                sub_category_options = [''] + classifier.get_sub_categories(selected_main)
                                sub_category_index = sub_category_options.index(current_sub) if current_sub in sub_category_options else 0
                                
                                selected_sub = st.selectbox(
                                    "ä¸­ã‚«ãƒ†ã‚´ãƒª",
                                    options=sub_category_options,
                                    index=sub_category_index,
                                    key=f"sub_cat_{i}"
                                )
                            else:
                                selected_sub = ""
                            
                            # ç·¨é›†ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                            chunk['manual_main_category'] = selected_main
                            chunk['manual_sub_category'] = selected_sub
                            
                            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’è¿½åŠ 
                            st.write(f"  - ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®æ‰‹å‹•ã‚«ãƒ†ã‚´ãƒªè¨­å®š: {selected_main} / {selected_sub}")
                            
                            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                            st.session_state['preview_chunks'] = preview_chunks_list
                            
                            # ãƒãƒ£ãƒ³ã‚¯å›ºæœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨­å®š
                            st.markdown("#### ğŸ”§ ãƒãƒ£ãƒ³ã‚¯å›ºæœ‰è¨­å®š")
                            st.markdown("ã“ã®ãƒãƒ£ãƒ³ã‚¯ã«ç‰¹æœ‰ã®è¨­å®šã‚’è¡Œã„ã¾ã™")
                            
                            # ãƒãƒ£ãƒ³ã‚¯å›ºæœ‰ã®ä½ç½®æƒ…å ±
                            st.markdown("**ğŸ“ ã“ã®ãƒãƒ£ãƒ³ã‚¯ã®ä½ç½®æƒ…å ±**")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                chunk_latitude = st.number_input(
                                    "ç·¯åº¦",
                                    min_value=-90.0,
                                    max_value=90.0,
                                    value=chunk.get('chunk_location', {}).get('latitude', None),
                                    step=0.0001,
                                    format="%.4f",
                                    key=f"chunk_latitude_{i}",
                                    help="ç·¯åº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š35.9056ï¼‰"
                                )
                                
                                chunk_longitude = st.number_input(
                                    "çµŒåº¦",
                                    min_value=-180.0,
                                    max_value=180.0,
                                    value=chunk.get('chunk_location', {}).get('longitude', None),
                                    step=0.0001,
                                    format="%.4f",
                                    key=f"chunk_longitude_{i}",
                                    help="çµŒåº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š139.4852ï¼‰"
                                )
                            
                            with col2:
                                chunk_address = st.text_input(
                                    "ä½æ‰€",
                                    value=chunk.get('chunk_location', {}).get('address', ""),
                                    placeholder="ä½æ‰€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰",
                                    key=f"chunk_address_{i}",
                                    help="è©³ç´°ãªä½æ‰€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                                )
                                
                                # ãƒãƒ£ãƒ³ã‚¯å›ºæœ‰ã®ä½ç½®æƒ…å ±ã®æ¤œè¨¼
                                if chunk_latitude is not None and chunk_longitude is not None:
                                    st.success(f"âœ… ä½ç½®æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
                                    st.write(f"ç·¯åº¦: {chunk_latitude}, çµŒåº¦: {chunk_longitude}")
                                    if chunk_address:
                                        st.write(f"ä½æ‰€: {chunk_address}")
                                else:
                                    st.info("â„¹ï¸ ä½ç½®æƒ…å ±ã¯ä»»æ„ã§ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                            
                            # ãƒãƒ£ãƒ³ã‚¯å›ºæœ‰ã®è¨­å®šã‚’ä¿å­˜
                            chunk['chunk_location'] = {
                                'latitude': chunk_latitude,
                                'longitude': chunk_longitude,
                                'address': chunk_address
                            }
                            
                            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                            st.session_state['preview_chunks'] = preview_chunks_list
                            
                            # è³ªå•ä¾‹è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
                            st.markdown("#### ğŸ’¬ è³ªå•ä¾‹è¨­å®š")
                            st.markdown("ã“ã®ãƒãƒ£ãƒ³ã‚¯ã«é–¢é€£ã™ã‚‹è³ªå•ä¾‹ã‚’AIã§ç”Ÿæˆãƒ»ç·¨é›†ã§ãã¾ã™ï¼ˆæ¤œç´¢æ™‚ã«å„ªå…ˆã•ã‚Œã¾ã™ï¼‰")
                            
                            # è³ªå•ä¾‹ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
                            question_generator = QuestionExampleGenerator()
                            
                            # æ—¢å­˜ã®è³ªå•ä¾‹ã‚’å–å¾—
                            existing_examples = chunk.get('question_examples', [])
                            existing_text = '\n'.join(existing_examples) if existing_examples else ''
                            
                            # AIç”Ÿæˆãƒœã‚¿ãƒ³
                            col1, col2 = st.columns(2)
                            with col1:
                                if st.button(f"ğŸ¤– AIã§è³ªå•ä¾‹ã‚’ç”Ÿæˆ", key=f"generate_questions_{i}"):
                                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¨­å®šã—ã¦expanderã‚’é–‹ã„ãŸçŠ¶æ…‹ã«ã™ã‚‹
                                    st.session_state[f"generate_questions_{i}"] = True
                                    st.session_state[f"chunk_expander_{i}"] = True
                                    
                                    try:
                                        with st.spinner(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®è³ªå•ä¾‹ã‚’ç”Ÿæˆä¸­..."):
                                            # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—
                                            category = ""
                                            subcategory = ""
                                            if 'ai_classification' in chunk:
                                                ai_result = chunk['ai_classification']
                                                category = ai_result.get('main_category', '')
                                                subcategory = ai_result.get('sub_category', '')
                                            elif 'manual_main_category' in chunk and chunk['manual_main_category']:
                                                category = chunk['manual_main_category']
                                                subcategory = chunk.get('manual_sub_category', '')
                                            
                                            # è³ªå•ä¾‹ã‚’ç”Ÿæˆ
                                            generated_questions = question_generator.generate_question_examples(
                                                chunk['text'], 
                                                category, 
                                                subcategory
                                            )
                                            
                                            if generated_questions:
                                                # ç”Ÿæˆã•ã‚ŒãŸè³ªå•ä¾‹ã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                                                chunk['question_examples'] = generated_questions
                                                
                                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                                                st.session_state['preview_chunks'] = preview_chunks_list
                                                
                                                st.success(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®è³ªå•ä¾‹ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                                                st.write(f"ç”Ÿæˆã•ã‚ŒãŸè³ªå•ä¾‹: {len(generated_questions)}å€‹")
                                            else:
                                                st.warning("âš ï¸ è³ªå•ä¾‹ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                                                
                                    except Exception as e:
                                        st.error(f"è³ªå•ä¾‹ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            
                            with col2:
                                if existing_examples:
                                    if st.button(f"ğŸ”§ æ—¢å­˜ã®è³ªå•ä¾‹ã‚’æ”¹å–„", key=f"improve_questions_{i}"):
                                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¨­å®šã—ã¦expanderã‚’é–‹ã„ãŸçŠ¶æ…‹ã«ã™ã‚‹
                                        st.session_state[f"improve_questions_{i}"] = True
                                        st.session_state[f"chunk_expander_{i}"] = True
                                        
                                        try:
                                            with st.spinner(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®è³ªå•ä¾‹ã‚’æ”¹å–„ä¸­..."):
                                                # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—
                                                category = ""
                                                subcategory = ""
                                                if 'ai_classification' in chunk:
                                                    ai_result = chunk['ai_classification']
                                                    category = ai_result.get('main_category', '')
                                                    subcategory = ai_result.get('sub_category', '')
                                                elif 'manual_main_category' in chunk and chunk['manual_main_category']:
                                                    category = chunk['manual_main_category']
                                                    subcategory = chunk.get('manual_sub_category', '')
                                                
                                                # è³ªå•ä¾‹ã‚’æ”¹å–„
                                                improved_questions = question_generator.improve_question_examples(
                                                    chunk['text'],
                                                    existing_examples,
                                                    category,
                                                    subcategory
                                                )
                                                
                                                if improved_questions:
                                                    # æ”¹å–„ã•ã‚ŒãŸè³ªå•ä¾‹ã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                                                    chunk['question_examples'] = improved_questions
                                                    
                                                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                                                    st.session_state['preview_chunks'] = preview_chunks_list
                                                    
                                                    st.success(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®è³ªå•ä¾‹ã‚’æ”¹å–„ã—ã¾ã—ãŸï¼")
                                                    st.write(f"æ”¹å–„ã•ã‚ŒãŸè³ªå•ä¾‹: {len(improved_questions)}å€‹")
                                                else:
                                                    st.warning("âš ï¸ è³ªå•ä¾‹ã®æ”¹å–„ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                                                    
                                        except Exception as e:
                                            st.error(f"è³ªå•ä¾‹æ”¹å–„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            
                            # ç¾åœ¨ã®è³ªå•ä¾‹ã‚’è¡¨ç¤ºãƒ»ç·¨é›†
                            current_examples = chunk.get('question_examples', [])
                            current_text = '\n'.join(current_examples) if current_examples else ''
                            
                            # è³ªå•ä¾‹ã®å…¥åŠ›ãƒ»ç·¨é›†
                            question_examples_text = st.text_area(
                                "è³ªå•ä¾‹ï¼ˆç·¨é›†å¯èƒ½ï¼‰",
                                value=current_text,
                                placeholder="ã“ã®ãƒãƒ£ãƒ³ã‚¯ã«é–¢é€£ã™ã‚‹è³ªå•ä¾‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ1è¡Œã«1ã¤ã®è³ªå•ï¼‰\nä¾‹ï¼š\nã“ã®ç‰©ä»¶ã®å®Œæˆæ™‚æœŸã¯ã„ã¤ã§ã™ã‹ï¼Ÿ\næœ€å¯„ã‚Šé§…ã¾ã§ã®è·é›¢ã¯ï¼Ÿ\nå‘¨è¾ºã®å­¦æ ¡ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
                                height=150,
                                key=f"question_examples_{i}",
                                help="ã“ã®ãƒãƒ£ãƒ³ã‚¯ã«é–¢é€£ã™ã‚‹è³ªå•ä¾‹ã‚’1è¡Œã«1ã¤ãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚å…¥åŠ›ã•ã‚ŒãŸè³ªå•ä¾‹ã¯æ¤œç´¢æ™‚ã«å„ªå…ˆã•ã‚Œã¾ã™ã€‚"
                            )
                            
                            # è³ªå•ä¾‹ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                            if question_examples_text.strip():
                                chunk_question_examples = [q.strip() for q in question_examples_text.split('\n') if q.strip()]
                                chunk['question_examples'] = chunk_question_examples
                            else:
                                chunk['question_examples'] = []
                            
                            # è³ªå•ä¾‹ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                            if chunk['question_examples']:
                                st.info(f"ğŸ“Š ç¾åœ¨ã®è³ªå•ä¾‹: {len(chunk['question_examples'])}å€‹")
                                # è³ªå•ä¾‹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                with st.expander("ğŸ‘€ è³ªå•ä¾‹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                                    for j, question in enumerate(chunk['question_examples'], 1):
                                        st.write(f"{j}. {question}")
                            else:
                                st.info("â„¹ï¸ è³ªå•ä¾‹ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIç”Ÿæˆãƒœã‚¿ãƒ³ã‚’ä½¿ç”¨ã—ã¦è³ªå•ä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
                            
                            # å›ç­”ä¾‹è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
                            st.markdown("#### ğŸ’¡ å›ç­”ä¾‹è¨­å®š")
                            st.markdown("ã“ã®ãƒãƒ£ãƒ³ã‚¯ã«é–¢é€£ã™ã‚‹è³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã‚’AIã§ç”Ÿæˆãƒ»ç·¨é›†ã§ãã¾ã™")
                            
                            # æ—¢å­˜ã®å›ç­”ä¾‹ã‚’å–å¾—
                            existing_qa_pairs = chunk.get('answer_examples', [])
                            
                            # AIç”Ÿæˆãƒœã‚¿ãƒ³
                            col1, col2 = st.columns(2)
                            with col1:
                                if st.button(f"ğŸ¤– AIã§å›ç­”ä¾‹ã‚’ç”Ÿæˆ", key=f"generate_answers_{i}"):
                                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¨­å®šã—ã¦expanderã‚’é–‹ã„ãŸçŠ¶æ…‹ã«ã™ã‚‹
                                    st.session_state[f"generate_answers_{i}"] = True
                                    st.session_state[f"chunk_expander_{i}"] = True
                                    
                                    try:
                                        with st.spinner(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å›ç­”ä¾‹ã‚’ç”Ÿæˆä¸­..."):
                                            # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—
                                            category = ""
                                            subcategory = ""
                                            if 'ai_classification' in chunk:
                                                ai_result = chunk['ai_classification']
                                                category = ai_result.get('main_category', '')
                                                subcategory = ai_result.get('sub_category', '')
                                            elif 'manual_main_category' in chunk and chunk['manual_main_category']:
                                                category = chunk['manual_main_category']
                                                subcategory = chunk.get('manual_sub_category', '')
                                            
                                            # å›ç­”ä¾‹ã‚’ç”Ÿæˆ
                                            generated_qa_pairs = question_generator.generate_answer_examples(
                                                chunk['text'], 
                                                category, 
                                                subcategory
                                            )
                                            
                                            if generated_qa_pairs:
                                                # ç”Ÿæˆã•ã‚ŒãŸå›ç­”ä¾‹ã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                                                chunk['answer_examples'] = generated_qa_pairs
                                                
                                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                                                st.session_state['preview_chunks'] = preview_chunks_list
                                                
                                                st.success(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å›ç­”ä¾‹ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                                                st.write(f"ç”Ÿæˆã•ã‚ŒãŸå›ç­”ä¾‹: {len(generated_qa_pairs)}å€‹")
                                            else:
                                                st.warning("âš ï¸ å›ç­”ä¾‹ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                                                
                                    except Exception as e:
                                        st.error(f"å›ç­”ä¾‹ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            
                            with col2:
                                if existing_qa_pairs:
                                    if st.button(f"ğŸ”§ æ—¢å­˜ã®å›ç­”ä¾‹ã‚’æ”¹å–„", key=f"improve_answers_{i}"):
                                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¨­å®šã—ã¦expanderã‚’é–‹ã„ãŸçŠ¶æ…‹ã«ã™ã‚‹
                                        st.session_state[f"improve_answers_{i}"] = True
                                        st.session_state[f"chunk_expander_{i}"] = True
                                        
                                        try:
                                            with st.spinner(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å›ç­”ä¾‹ã‚’æ”¹å–„ä¸­..."):
                                                # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—
                                                category = ""
                                                subcategory = ""
                                                if 'ai_classification' in chunk:
                                                    ai_result = chunk['ai_classification']
                                                    category = ai_result.get('main_category', '')
                                                    subcategory = ai_result.get('sub_category', '')
                                                elif 'manual_main_category' in chunk and chunk['manual_main_category']:
                                                    category = chunk['manual_main_category']
                                                    subcategory = chunk.get('manual_sub_category', '')
                                                
                                                # å›ç­”ä¾‹ã‚’æ”¹å–„
                                                improved_qa_pairs = question_generator.improve_answer_examples(
                                                    chunk['text'],
                                                    existing_qa_pairs,
                                                    category,
                                                    subcategory
                                                )
                                                
                                                if improved_qa_pairs:
                                                    # æ”¹å–„ã•ã‚ŒãŸå›ç­”ä¾‹ã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                                                    chunk['answer_examples'] = improved_qa_pairs
                                                    
                                                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                                                    st.session_state['preview_chunks'] = preview_chunks_list
                                                    
                                                    st.success(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å›ç­”ä¾‹ã‚’æ”¹å–„ã—ã¾ã—ãŸï¼")
                                                    st.write(f"æ”¹å–„ã•ã‚ŒãŸå›ç­”ä¾‹: {len(improved_qa_pairs)}å€‹")
                                                else:
                                                    st.warning("âš ï¸ å›ç­”ä¾‹ã®æ”¹å–„ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                                                    
                                        except Exception as e:
                                            st.error(f"å›ç­”ä¾‹æ”¹å–„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            
                            # ç¾åœ¨ã®å›ç­”ä¾‹ã‚’è¡¨ç¤ºãƒ»ç·¨é›†
                            current_qa_pairs = chunk.get('answer_examples', [])
                            
                            # å›ç­”ä¾‹ã®è¡¨ç¤ºãƒ»ç·¨é›†
                            if current_qa_pairs:
                                st.info(f"ğŸ“Š ç¾åœ¨ã®å›ç­”ä¾‹: {len(current_qa_pairs)}å€‹")
                                
                                # å›ç­”ä¾‹ã®ç·¨é›†ç”¨UI
                                for j, qa_pair in enumerate(current_qa_pairs):
                                    with st.expander(f"å›ç­”ä¾‹ {j+1}", expanded=False):
                                        # è³ªå•ã®ç·¨é›†
                                        question = st.text_area(
                                            "è³ªå•",
                                            value=qa_pair.get('question', ''),
                                            key=f"answer_question_{i}_{j}",
                                            help="è³ªå•ã‚’ç·¨é›†ã—ã¦ãã ã•ã„"
                                        )
                                        
                                        # å›ç­”ã®ç·¨é›†
                                        answer = st.text_area(
                                            "å›ç­”",
                                            value=qa_pair.get('answer', ''),
                                            key=f"answer_answer_{i}_{j}",
                                            help="å›ç­”ã‚’ç·¨é›†ã—ã¦ãã ã•ã„"
                                        )
                                        
                                        # æ›´æ–°ã•ã‚ŒãŸãƒšã‚¢ã‚’ä¿å­˜
                                        current_qa_pairs[j] = {
                                            "question": question,
                                            "answer": answer
                                        }
                                
                                # æ–°ã—ã„å›ç­”ä¾‹ã‚’è¿½åŠ 
                                if st.button(f"â• æ–°ã—ã„å›ç­”ä¾‹ã‚’è¿½åŠ ", key=f"add_answer_{i}"):
                                    current_qa_pairs.append({
                                        "question": "",
                                        "answer": ""
                                    })
                                    st.session_state['preview_chunks'] = preview_chunks_list
                                    st.rerun()
                                
                                # å›ç­”ä¾‹ã‚’ãƒãƒ£ãƒ³ã‚¯ã«ä¿å­˜
                                chunk['answer_examples'] = current_qa_pairs
                                
                                # å›ç­”ä¾‹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                                with st.expander("ğŸ‘€ å›ç­”ä¾‹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                                    for j, qa_pair in enumerate(current_qa_pairs, 1):
                                        st.markdown(f"**{j}. è³ªå•:** {qa_pair.get('question', '')}")
                                        st.markdown(f"**å›ç­”:** {qa_pair.get('answer', '')}")
                                        st.markdown("---")
                            else:
                                st.info("â„¹ï¸ å›ç­”ä¾‹ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIç”Ÿæˆãƒœã‚¿ãƒ³ã‚’ä½¿ç”¨ã—ã¦å›ç­”ä¾‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
                            
                            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å³åº§ã«æ›´æ–°
                            st.session_state['preview_chunks'] = preview_chunks_list
                    
                    # åˆ†å‰²ã®å“è³ªãƒã‚§ãƒƒã‚¯
                    st.markdown("#### ğŸ” åˆ†å‰²å“è³ªãƒã‚§ãƒƒã‚¯")
                    
                    # çŸ­ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã®è­¦å‘Š
                    short_chunks = [chunk for chunk in preview_chunks_list if len(chunk['text']) < 50]
                    if short_chunks:
                        st.warning(f"âš ï¸ {len(short_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ãŒ50æ–‡å­—æœªæº€ã§ã™ã€‚å†…å®¹ãŒä¸ååˆ†ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                    
                    # é•·ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã®è­¦å‘Š
                    long_chunks = [chunk for chunk in preview_chunks_list if len(chunk['text']) > 2000]
                    if long_chunks:
                        st.warning(f"âš ï¸ {len(long_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ãŒ2000æ–‡å­—ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
                    
                    # æ¨å¥¨äº‹é …
                    if not short_chunks and not long_chunks:
                        st.success("âœ… ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®å“è³ªã¯è‰¯å¥½ã§ã™ã€‚")
                    
                    # ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®ä½¿ç”¨çŠ¶æ³
                    st.markdown("#### ğŸ“Š ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ä½¿ç”¨çŠ¶æ³")
                    separator_counts = {}
                    for chunk in preview_chunks_list:
                        if 'separators_used' in chunk['metadata']:
                            for sep in chunk['metadata']['separators_used']:
                                separator_counts[sep] = separator_counts.get(sep, 0) + 1
                    
                    if separator_counts:
                        for sep, count in separator_counts.items():
                            st.markdown(f"- `{sep}`: {count}å›ä½¿ç”¨")
                    else:
                        st.info("ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®ä½¿ç”¨çŠ¶æ³ã¯è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else:
                    st.warning("âš ï¸ ãƒãƒ£ãƒ³ã‚¯ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    
                    # ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®ç¢ºèªã‚’ä¿ƒã™
                    st.markdown("#### ğŸ’¡ ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®ç¢ºèª")
                    st.markdown("ä»¥ä¸‹ã®ç‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š")
                    st.markdown("1. ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ãŒæ­£ã—ãå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹")
                    st.markdown("2. ãƒ†ã‚­ã‚¹ãƒˆå†…ã«ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹")
                    st.markdown("3. ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®å‰å¾Œã«é©åˆ‡ãªæ”¹è¡ŒãŒã‚ã‚‹ã‹")
                    
                    # ç¾åœ¨ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    st.markdown("**ç¾åœ¨ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿:**")
                    st.code(chunk_separators)
            
            # ä¿å­˜ãƒœã‚¿ãƒ³
            if st.button("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"):
                try:
                    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã€ãªã„å ´åˆã¯æ–°ã—ãç”Ÿæˆ
                        if 'preview_chunks' in st.session_state:
                            chunks = st.session_state['preview_chunks']
                            st.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã—ã¾ã—ãŸ")
                        else:
                            chunks = advanced_manual_chunk_split(edited_text, chunk_separators)
                            st.info(f"æ–°ã—ã{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
                        
                        if not chunks:
                            st.error("ãƒãƒ£ãƒ³ã‚¯ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            return
                        
                        st.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
                        
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        for i, chunk in enumerate(chunks):
                            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
                            st.write(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å‡¦ç†:")
                            st.write(f"  - æ‰‹å‹•ã‚«ãƒ†ã‚´ãƒª: {chunk.get('manual_main_category', 'ãªã—')} / {chunk.get('manual_sub_category', 'ãªã—')}")
                            st.write(f"  - AIåˆ†é¡: {chunk.get('ai_classification', 'ãªã—')}")
                            st.write(f"  - è³ªå•ä¾‹: {chunk.get('question_examples', [])}")
                            st.write(f"  - å›ç­”ä¾‹: {chunk.get('answer_examples', [])}")
                            st.write(f"  - æ¤œè¨¼æ¸ˆã¿: {verified}")
                            st.write(f"  - æ›´æ–°ã‚¿ã‚¤ãƒ—: {timestamp_type}")
                            st.write(f"  - ä½ç½®æƒ…å ±: ç·¯åº¦{chunk.get('chunk_location', {}).get('latitude', None)}, çµŒåº¦{chunk.get('chunk_location', {}).get('longitude', None)}, ä½æ‰€{chunk.get('chunk_location', {}).get('address', '')}")
                            
                            # åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                            metadata = {
                                "main_category": "",
                                "sub_category": "",
                                "city": city if city else "",
                                "created_date": created_date.isoformat() if created_date else "",
                                "upload_date": upload_date.isoformat(),
                                "source": source if source else "",
                                "question_examples": chunk.get('question_examples', []),
                                "answer_examples": chunk.get('answer_examples', []),
                                "verified": verified,
                                "timestamp_type": timestamp_type,
                                "valid_for": selected_periods if selected_periods else [],
                                "latitude": chunk.get('chunk_location', {}).get('latitude') if chunk.get('chunk_location', {}).get('latitude') is not None else 0.0,
                                "longitude": chunk.get('chunk_location', {}).get('longitude') if chunk.get('chunk_location', {}).get('longitude') is not None else 0.0,
                                "address": chunk.get('chunk_location', {}).get('address', '')
                            }
                            
                            # ã‚«ãƒ†ã‚´ãƒªã®è¨­å®šï¼ˆå„ªå…ˆé †ä½: æ‰‹å‹•ç·¨é›† > AIåˆ†é¡ï¼‰
                            st.write(f"  - ã‚«ãƒ†ã‚´ãƒªè¨­å®šã®ç¢ºèª:")
                            st.write(f"    - manual_main_category: {chunk.get('manual_main_category', 'ãªã—')}")
                            st.write(f"    - manual_sub_category: {chunk.get('manual_sub_category', 'ãªã—')}")
                            st.write(f"    - ai_classification: {chunk.get('ai_classification', 'ãªã—')}")
                            
                            if 'manual_main_category' in chunk and chunk['manual_main_category']:
                                metadata["main_category"] = chunk['manual_main_category']
                                metadata["sub_category"] = chunk.get('manual_sub_category', '')
                                st.write(f"  - æ‰‹å‹•ã‚«ãƒ†ã‚´ãƒªã‚’è¨­å®š: {metadata['main_category']} / {metadata['sub_category']}")
                            elif 'ai_classification' in chunk:
                                ai_result = chunk['ai_classification']
                                metadata["main_category"] = ai_result.get('main_category', '')
                                metadata["sub_category"] = ai_result.get('sub_category', '')
                                # AIåˆ†é¡ã®è©³ç´°æƒ…å ±ã‚‚ä¿å­˜
                                metadata["ai_confidence"] = ai_result.get('confidence', 0.0)
                                metadata["ai_reasoning"] = ai_result.get('reasoning', '')
                                st.write(f"  - AIåˆ†é¡ã‚’è¨­å®š: {metadata['main_category']} / {metadata['sub_category']}")
                            else:
                                st.write(f"  - ã‚«ãƒ†ã‚´ãƒªæœªè¨­å®š")
                            
                            # ãƒãƒ£ãƒ³ã‚¯ã®åŸºæœ¬æƒ…å ±
                            chunk["metadata"] = metadata
                            chunk["filename"] = uploaded_file.name
                            chunk["chunk_id"] = chunk["id"]
                            
                            # AIåˆ†é¡æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
                            if 'ai_classification' in chunk:
                                chunk["metadata"]["ai_classification"] = chunk['ai_classification']
                            
                            # æœ€çµ‚çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                            st.write(f"  - æœ€çµ‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata}")
                        
                        with st.spinner("Pineconeã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                            pinecone_service.upload_chunks(chunks)
                            st.success("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            
                            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                            if 'preview_chunks' in st.session_state:
                                del st.session_state['preview_chunks']
                            if 'show_preview' in st.session_state:
                                del st.session_state['show_preview']
                except ValueError as e:
                    st.error(str(e))
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}") 